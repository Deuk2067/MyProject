{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e0de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%config Completer.use_jedi = False\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['font.family'] = 'NanumGothicCoding'\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b77f9",
   "metadata": {},
   "source": [
    "네이버는 100위까지 밖에 없어서 실시간, 일간, 주간, 월간 4가지가 있다 근데 장르가 안보이기에 클릭해서 페이지 이동 후 정보 스크롤 하는 식으로 해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06693ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일간 Top 100\n",
    "targetSite = 'https://series.naver.com/novel/top100List.series' # 네이버 시리즈 Top 100 처음 띄우기\n",
    "driver = webdriver.Chrome() \n",
    "driver.get(targetSite)\n",
    "time.sleep(0.5)\n",
    "request = requests.get(targetSite)\n",
    "html = request.text\n",
    "soup = BeautifulSoup(html, 'html.parser') # 크롤링 하려는 페이지 띄우기\n",
    "\n",
    "NaverSeries_Day_Genre = [] # 장르 저장할 리스트\n",
    "NaverSeries_Day_Titles = [] # 제목 저장할 리스트\n",
    "NaverSeries_Day_Author = [] # 작가 저장할 리스트\n",
    "NaverSeries_Day_Point = [] # 평점 리스트\n",
    "NaverSeries_Day_Ranking = [i+1 for i in range(100) ]\n",
    "\n",
    "# 첫 페이지 1~20위 클릭 후 정보 확인\n",
    "#//*[@id=\"content\"]/div/ul/li[1]/div[2]/h3/a # 1위\n",
    "#//*[@id=\"content\"]/div/ul/li[2]/div[2]/h3/a # 2위\n",
    "#//*[@id=\"content\"]/div/ul/li[3]/div[2]/h3/a # 3위\n",
    "\n",
    "for i in range(1, 21, 1):\n",
    "    driver.find_element(By.XPATH, f'//*[@id=\"content\"]/div/ul/li[{i}]/div[2]/h3/a').click() # i번째 소설 들어감\n",
    "    try:\n",
    "        NaverSeries_Day_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/h2').text) # 제목\n",
    "        NaverSeries_Day_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/div[1]/em').text) # 평점\n",
    "    except:\n",
    "        NaverSeries_Day_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/h2').text) # 제목\n",
    "        NaverSeries_Day_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/em').text) # 평점        \n",
    "    NaverSeries_Day_Genre.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[2]/span/a').text) # 장르\n",
    "    NaverSeries_Day_Author.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[3]/a').text) # 작가\n",
    "    driver.back()# i번 소설 크로링 후 전 페이지로\n",
    "    \n",
    "for i in range(1,5):\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[1] # 21~40위 페이지 띄움\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[2] # 41~60위 띄움\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[3] # 61~80\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[4] # 81~100\n",
    "    driver.find_element(By.XPATH, f'//*[@id=\"content\"]/div/div[2]/a[{i}]').click()\n",
    "    for j in range(1, 21, 1):\n",
    "        driver.find_element(By.XPATH, f'//*[@id=\"content\"]/div/ul/li[{j}]/div[2]/h3/a').click() # i번째 소설 들어감\n",
    "        try:\n",
    "            NaverSeries_Day_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/h2').text) # 제목\n",
    "            NaverSeries_Day_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/div[1]/em').text) # 평점\n",
    "        except:\n",
    "            NaverSeries_Day_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/h2').text) # 제목\n",
    "            NaverSeries_Day_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/em').text) # 평점        \n",
    "        NaverSeries_Day_Genre.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[2]/span/a').text) # 장르\n",
    "        NaverSeries_Day_Author.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[3]/a').text) # 작가\n",
    "        driver.back()# i번 소설 크로링 후 전 페이지로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7d8a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NaverSeries_Day = pd.DataFrame(\n",
    "    {'제목': NaverSeries_Day_Titles, '장르': NaverSeries_Day_Genre,'작가': NaverSeries_Day_Author, '평점': NaverSeries_Day_Point},\n",
    "    index = NaverSeries_Day_Ranking) \n",
    "\n",
    "# 네이버 일간 top 100 끝\n",
    "\n",
    "all_genres = pd.Series(NaverSeries_Day['장르'].unique())\n",
    "#print(all_genres)\n",
    "for genre in all_genres:\n",
    "    NaverSeries_Day[genre] = (NaverSeries_Day['장르'] == genre)\n",
    "NaverSeries_Day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58256856",
   "metadata": {},
   "source": [
    "주간 top100도 위와 같은 식으로 실행 해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7035f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "NaverSeries_Week_Genre = [] # 장르 저장할 리스트 생성 및 초기화\n",
    "NaverSeries_Week_Titles = [] # 제목 저장할 리스트\n",
    "NaverSeries_Week_Author = [] # 작가 저장할 리스트\n",
    "NaverSeries_Week_Point = [] # 평점 리스트\n",
    "NaverSeries_Week_Ranking = [i+1 for i in range(100) ]\n",
    "\n",
    "driver.find_element(By.XPATH, '//*[@id=\"container\"]/div[1]/ul/li[3]/a').click()\n",
    "\n",
    "for i in range(1, 21, 1):\n",
    "    driver.find_element(By.XPATH, f'//*[@id=\"content\"]/div/ul/li[{i}]/div[2]/h3/a').click() # i번째 소설 들어감\n",
    "    try:\n",
    "        NaverSeries_Week_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/h2').text) # 제목\n",
    "        NaverSeries_Week_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/div[1]/em').text) # 평점\n",
    "    except:\n",
    "        NaverSeries_Week_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/h2').text) # 제목\n",
    "        NaverSeries_Week_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/em').text) # 평점        \n",
    "    NaverSeries_Week_Genre.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[2]/span/a').text) # 장르\n",
    "    NaverSeries_Week_Author.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[3]/a').text) # 작가\n",
    "    driver.back()# i번 소설 크로링 후 전 페이지로\n",
    "    \n",
    "for i in range(1,5):\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[1] # 21~40위 페이지 띄움\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[2] # 41~60위 띄움\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[3] # 61~80\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[4] # 81~100\n",
    "    driver.find_element(By.XPATH, f'//*[@id=\"content\"]/div/div[2]/a[{i}]').click()\n",
    "    for j in range(1, 21, 1):\n",
    "        driver.find_element(By.XPATH, f'//*[@id=\"content\"]/div/ul/li[{j}]/div[2]/h3/a').click() # i번째 소설 들어감\n",
    "        try:\n",
    "            NaverSeries_Week_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/h2').text) # 제목\n",
    "            NaverSeries_Week_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/div[1]/em').text) # 평점\n",
    "        except:\n",
    "            NaverSeries_Week_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/h2').text) # 제목\n",
    "            NaverSeries_Week_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/em').text) # 평점        \n",
    "        NaverSeries_Week_Genre.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[2]/span/a').text) # 장르\n",
    "        NaverSeries_Week_Author.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[3]/a').text) # 작가\n",
    "        driver.back()# i번 소설 크로링 후 전 페이지로\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e90700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NaverSeries_Week = pd.DataFrame(\n",
    "    {'제목': NaverSeries_Week_Titles, '장르': NaverSeries_Week_Genre,'작가': NaverSeries_Week_Author, '평점': NaverSeries_Week_Point},\n",
    "    index = NaverSeries_Week_Ranking) \n",
    "\n",
    "# 네이버 일간 top 100 끝\n",
    "\n",
    "all_genres = pd.Series(NaverSeries_Week['장르'].unique())\n",
    "#print(all_genres)\n",
    "for genre in all_genres:\n",
    "    NaverSeries_Week[genre] = (NaverSeries_Week['장르'] == genre)\n",
    "NaverSeries_Week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NaverSeries_Month_Genre = [] # 장르 저장할 리스트 생성 및 초기화\n",
    "NaverSeries_Month_Titles = [] # 제목 저장할 리스트\n",
    "NaverSeries_Month_Author = [] # 작가 저장할 리스트\n",
    "NaverSeries_Month_Point = [] # 평점 리스트\n",
    "NaverSeries_Month_Ranking = [i+1 for i in range(100) ]\n",
    "\n",
    "driver.find_element(By.XPATH, '//*[@id=\"container\"]/div[1]/ul/li[3]/a').click()\n",
    "\n",
    "for i in range(1, 21, 1):\n",
    "    driver.find_element(By.XPATH, f'//*[@id=\"content\"]/div/ul/li[{i}]/div[2]/h3/a').click() # i번째 소설 들어감\n",
    "    try:\n",
    "        NaverSeries_Month_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/h2').text) # 제목\n",
    "        NaverSeries_Month_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/div[1]/em').text) # 평점\n",
    "    except:\n",
    "        NaverSeries_Month_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/h2').text) # 제목\n",
    "        NaverSeries_Month_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/em').text) # 평점      \n",
    "    NaverSeries_Month_Genre.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[2]/span/a').text) # 장르\n",
    "    NaverSeries_Month_Author.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[3]/a').text) # 작가\n",
    "    driver.back()# i번 소설 크로링 후 전 페이지로\n",
    "    \n",
    "for i in range(1,5):\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[1] # 21~40위 페이지 띄움\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[2] # 41~60위 띄움\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[3] # 61~80\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[4] # 81~100\n",
    "    driver.find_element(By.XPATH, f'//*[@id=\"content\"]/div/div[2]/a[{i}]').click()\n",
    "    for j in range(1, 21, 1):\n",
    "        driver.find_element(By.XPATH, f'//*[@id=\"content\"]/div/ul/li[{j}]/div[2]/h3/a').click() # i번째 소설 들어감\n",
    "        try:\n",
    "            NaverSeries_Month_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/h2').text) # 제목\n",
    "            NaverSeries_Month_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/div[1]/em').text) # 평점\n",
    "        except:\n",
    "            NaverSeries_Month_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/h2').text) # 제목\n",
    "            NaverSeries_Month_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/em').text) # 평점        \n",
    "        NaverSeries_Month_Genre.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[2]/span/a').text) # 장르\n",
    "        NaverSeries_Month_Author.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[3]/a').text) # 작가\n",
    "        driver.back()# i번 소설 크로링 후 전 페이지로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4642dee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NaverSeries_Month = pd.DataFrame(\n",
    "    {'제목': NaverSeries_Month_Titles, '장르': NaverSeries_Month_Genre,'작가': NaverSeries_Month_Author, '평점': NaverSeries_Month_Point},\n",
    "    index = NaverSeries_Month_Ranking) \n",
    "\n",
    "# 네이버 일간 top 100 끝\n",
    "\n",
    "all_genres = pd.Series(NaverSeries_Month['장르'].unique())\n",
    "#print(all_genres)\n",
    "for genre in all_genres:\n",
    "    NaverSeries_Month[genre] = (NaverSeries_Month['장르'] == genre)\n",
    "NaverSeries_Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76869df5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NaverSeries_Now_Genre = [] # 장르 저장할 리스트 생성 및 초기화\n",
    "NaverSeries_Now_Titles = [] # 제목 저장할 리스트\n",
    "NaverSeries_Now_Author = [] # 작가 저장할 리스트\n",
    "NaverSeries_Now_Point = [] # 평점 리스트\n",
    "NaverSeries_Now_Ranking = [] # 랭킹\n",
    "\n",
    "driver.find_element(By.XPATH, '//*[@id=\"container\"]/div[1]/ul/li[1]/a').click()\n",
    "\n",
    "for i in range(1, 21, 1):\n",
    "    driver.find_element(By.XPATH, f'//*[@id=\"content\"]/div/ul/li[{i}]/div[2]/h3/a').click() # i번째 소설 들어감\n",
    "    if \"login\" in driver.current_url or \"adult\" in driver.current_url:\n",
    "        NaverSeries_Now_Titles.append(\"19금\")\n",
    "        NaverSeries_Now_Point.append(\"19금\")\n",
    "        NaverSeries_Now_Genre.append(\"19금\")\n",
    "        NaverSeries_Now_Author.append(\"19금\")\n",
    "        driver.back()\n",
    "        continue\n",
    "    try:\n",
    "        NaverSeries_Now_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/h2').text) # 제목\n",
    "        NaverSeries_Now_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/div[1]/em').text) # 평점\n",
    "    except:\n",
    "        NaverSeries_Now_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/h2').text) # 제목\n",
    "        NaverSeries_Now_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/em').text) # 평점      \n",
    "    NaverSeries_Now_Genre.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[2]/span/a').text) # 장르\n",
    "    NaverSeries_Now_Author.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[3]/a').text) # 작가\n",
    "    driver.back()# i번 소설 크로링 후 전 페이지로\n",
    "    \n",
    "for i in range(1,5):\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[1] # 21~40위 페이지 띄움\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[2] # 41~60위 띄움\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[3] # 61~80\n",
    "    # //*[@id=\"content\"]/div/div[2]/a[4] # 81~100\n",
    "    driver.find_element(By.XPATH, f'//*[@id=\"content\"]/div/div[2]/a[{i}]').click()\n",
    "    for j in range(1, 21, 1):\n",
    "        driver.find_element(By.XPATH, f'//*[@id=\"content\"]/div/ul/li[{j}]/div[2]/h3/a').click() # i번째 소설 들어감\n",
    "        if \"login\" in driver.current_url or \"adult\" in driver.current_url:\n",
    "            NaverSeries_Now_Titles.append(\"19금\")\n",
    "            NaverSeries_Now_Point.append(\"19금\")\n",
    "            NaverSeries_Now_Genre.append(\"19금\")\n",
    "            NaverSeries_Now_Author.append(\"19금\")            \n",
    "            driver.back()\n",
    "            continue\n",
    "        try:\n",
    "            NaverSeries_Now_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/h2').text) # 제목\n",
    "            NaverSeries_Now_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/div[1]/em').text) # 평점\n",
    "        except:\n",
    "            NaverSeries_Now_Titles.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/h2').text) # 제목\n",
    "            NaverSeries_Now_Point.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[2]/div[1]/em').text) # 평점     \n",
    "        NaverSeries_Now_Genre.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[2]/span/a').text) # 장르\n",
    "        NaverSeries_Now_Author.append(driver.find_element(By.XPATH, '//*[@id=\"content\"]/ul[1]/li/ul/li[3]/a').text) # 작가\n",
    "        driver.back()# i번 소설 크로링 후 전 페이지로\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33ffc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(NaverSeries_Now_Titles), len(NaverSeries_Now_Genre), len(NaverSeries_Now_Author), len(NaverSeries_Now_Point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a4c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "NaverSeries_Now = pd.DataFrame(\n",
    "    {'제목': NaverSeries_Now_Titles, '장르': NaverSeries_Now_Genre,'작가': NaverSeries_Now_Author, '평점': NaverSeries_Now_Point},\n",
    "    index = NaverSeries_Now_Ranking) \n",
    "\n",
    "# 네이버 일간 top 100 끝\n",
    "\n",
    "all_genres = pd.Series(NaverSeries_Now['장르'].unique())\n",
    "#print(all_genres)\n",
    "for genre in all_genres:\n",
    "    NaverSeries_Now[genre] = (NaverSeries_Now['장르'] == genre)\n",
    "NaverSeries_Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d870af",
   "metadata": {},
   "outputs": [],
   "source": [
    "NaverSeries_Now.to_csv('./data/NaverSeries_Now100.txt', sep = '\\t')\n",
    "NaverSeries_Day.to_csv('./data/NaverSeries_Day100.txt', sep = '\\t')\n",
    "NaverSeries_Week.to_csv('./data/NaverSeries_Week100.txt', sep = '\\t')\n",
    "NaverSeries_Month.to_csv('./data/NaverSeries_Month100.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ebda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=5\n",
    "print(i) # 5\n",
    "i+1\n",
    "print(i)\n",
    "i+=1\n",
    "print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
