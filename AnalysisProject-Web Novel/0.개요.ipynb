{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c3085ca",
   "metadata": {},
   "source": [
    "0.프로젝트 개요  \n",
    "\n",
    "웹소설을 좋아하는데 사이트마다 인기있거나 연재되는 소설의 분위기가 다르다는걸 느낌  \n",
    "생각해 보니 사이트별로 주로 보는 소설들도 다른 것 같고 순위권에 올라오는 소설 종류나 트랜드도 다르단걸 알게됨  \n",
    "사이트마다 소설 트렌드를 한눈에 알아 볼 수 있게 차트로 나타냈으면 좋겠다는 생각이 듬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22e164d",
   "metadata": {},
   "source": [
    "1. 사이트마다 주된 소설 트렌드를 알기 위해 데이터 수집이 필요함 직접 크롤링해서 수집하기로 결정함  \n",
    "    1-1. 문피아 실시간 유료 랭킹 200위 소설 데이터를 수집해서 현 시점 트랜드, 장르를 분석해봄 => 성공  \n",
    "    \n",
    "        (1). 실시간 순위를 모두 보려면 스크롤해야 해서 정적 크롤링을 사용하기로함  \n",
    "        (2). find_element(By.XPATH, '') 를 사용했는데 1 ~ 3위 소설과 나머지는 규칙성이 달라서 1~3위, 그외의 나머지로 나누어서 2번 작업해야했음.  \n",
    "        (3). 데이터프레임 만들기  \n",
    "        \n",
    "    1-2. 네이버 시리즈 실시간, 투데이, 주간, 월간 소설을 각각 100위 데이터를 수집 => (5) 아직 안함 \n",
    "    \n",
    "        (1). 네이버는 순위가 100위까지만 있어서 실시간, 투데이, 주간, 월간 4가지로 400개 데이터 수집  \n",
    "        (2). 처음 했던 문피아와 달리 20위씩 페이지 단위로 5페이지가 있어서 find_element(By.XPATH, '').clock()으로 5번 반복 하도록 코딩함.  \n",
    "        (3). 문피아는 지수를 따로 정해서 랭킹을 정하는데 시리즈의 경우 조회수, 좋아요 수를 기준으로 순위를 정하지만 조회수와 좋아요 수를 구할 수 없어서 평점을 수집함 \n",
    "        (4). 시리즈에서 실시간 랭킹 집계 중 19금 소설은 로그인, 성인 인증 요구 => '19금'으로 통일하고 나중에 전처리 과정에서 제외할 것 => NoSuchElementException 자꾸 발생되서 터짐 => 구글링으로 if \"login\" in driver.current_url or \"adult\" in driver.current_url: 조건 걸고 '19금'으로 통일함 => 성공, 나중에 전처리 과정에서 제외할 것\n",
    "        (5). 수집하고 보니까 코딩에서 중복된게 많이 보임 나중에 코딩 간결하게 만들것\n",
    "        \n",
    "    1-3. 카카오 페이지 실시간 랭킹 300위 데이터를 수집 => 성공  \n",
    "    \n",
    "        (1). 문피아, 시리즈랑 달리 find_element(By.XPATH, '') 가 안됨 원인 모름 => By.CSS_SELECTOR에서 링크만 따오고 하나씩 driver.get()으로 열고 find_element(By.XPATH, '')로 필요한 정보 수집  \n",
    "        (2). 시리즈처럼 19금 있어서 로그인 요구 => 시리즈랑 다르게 except NoSuchElementException: 으로 성공 '19금'으로 통일하고 후일 전처리  \n",
    "        (3). 장르 앞에 웹소설 텍스트가 붙어 있음 => 나중에 웹소설 때고 장르만 입력하는 전처리과정 필요\n",
    "        (4). 조회수는 있지만 총 조회수만 있고 개별 회차 마다 조회수는 없어서 총 조회수가 높다고 랭킹이 높지 않음 => 우선 평점만 수집  \n",
    "        \n",
    "      \n",
    "2. 수집한 데이터를 데이터프레임으로 만들고 쓰기 편하게 전처리를 실시함   \n",
    "\n",
    "    2-1. 각 데이터프레임에서 19금 작품 전부 drop => 성공  \n",
    "    2-2. 장르별 점유율이나 트렌드 장르를 알기 쉽도록 데이터프레임에 장르별로 컬럼 만들고 해당 장르 마다 True 넣어서 나중에 컬럼.sum()으로 점유율 구하기 쉽게 만듬 => 성공  \n",
    "    2-3. 데이터프레임.info() 사용해서 19금, null값 없는지 마지막 확인 => 성공   \n",
    "    2-4. ./data 폴더에 txt 파일로 저장 => 성공\n",
    "    \n",
    "3. 각 사이트별로 장르별 점유율 차트 만들기(시각화)  \n",
    "    3-1. 문피아  \n",
    "    \n",
    "    3-2. 네이버 시리즈  \n",
    "        (1) 데이터 불러와서 확인하는 도중 주간 순위와 월간 순위가 똑같은 오류 발견 => 수집 과정에서 주간 순위를 2번 크롤링 해왔음 => 수정함\n",
    "        (2) \n",
    "    3-3. 카카오페이지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0cfaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7caec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409faee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0918c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8e651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99185b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109563cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
