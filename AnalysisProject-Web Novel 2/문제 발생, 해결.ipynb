{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fdcd727",
   "metadata": {},
   "source": [
    "6/24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ae420",
   "metadata": {},
   "source": [
    "# 처음엔 하나씩 클릭해서 순위에 따른 순서대로 각 소설 관련 페이지를 띄우고 데이터를 크롤링하려 했으나\n",
    "# 클릭후 back() 하면 다시 아래로 스크롤을 해야하는 상황이 발생해서 방법을 바꿨다.\n",
    "# 빈 리스트를 만들고\n",
    "M_Links = []\n",
    "# 하이퍼링크를 가진 class의 내용을 가져온 후 \n",
    "M_Link_List = driver.find_elements(By.CLASS_NAME, 'best-item')\n",
    "# 하나씩 반복문을 돌리고\n",
    "for M_Link in M_Link_List:\n",
    "    # 위에 만든 빈 리스트에 하이퍼링크의 속성을 append 했다.\n",
    "    M_Links.append(M_Link.get_attribute('href'))\n",
    "# 그 과정에서 일종의 머리글, 태그 형식의 아무런 내용도 없는 None 값을 제거하는 것으로 순위권 소설의 모든 하이퍼 링크를 저장했다.    \n",
    "M_Links.remove(M_Links[3]) \n",
    "\n",
    "# 그 후에 다시 반복문을 돌려서\n",
    "for i in range(len(M_Links)):\n",
    "    driver.get(M_Links[i]) # 0부터 하나씩 저장된 하이퍼링크로 이동시키고 필요한 데이터 정보를 수집했다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ecd722",
   "metadata": {},
   "source": [
    "# 다시 문제가 발생했는데   \n",
    "# XPATH로 경로를 구해서 작가 이름을 리스트에 더하던 도중에 경로가 달라진 경우가 생겼고 try, except로 오류를 고쳤다.  \n",
    "try:  \n",
    "    Author.append(driver.find_element(By.XPATH, '//*[@id=\"board\"]/div[1]/div[3]/dl[1]/dd/a/strong').text) # 작가 추가  \n",
    "except:  \n",
    "    Author.append(driver.find_element(By.XPATH, '//*[@id=\"board\"]/div[1]/div[3]/dl[1]/dd').text) # 작가 추가    \n",
    "    \n",
    "# 위와 같은 문제가 선호작에도 똑같이 발생해서 같은 방법으로 고쳤다.  \n",
    "try:    \n",
    "    Author.append(driver.find_element(By.XPATH, '//*[@id=\"board\"]/div[1]/div[3]/dl[1]/dd/a/strong').text) # 작가 추가    \n",
    "    Favorite.append(driver.find_element(By.XPATH, '//*[@id=\"board\"]/div[1]/div[3]/div[2]/div[2]/a[1]/span/b').text) # 선작수 추가    \n",
    "except:    \n",
    "    Author.append(driver.find_element(By.XPATH, '//*[@id=\"board\"]/div[1]/div[3]/dl[1]/dd').text) # 작가 추가    \n",
    "    Favorite.append(driver.find_element(By.XPATH, '//*[@id=\"board\"]/div[1]/div[3]/div/div[2]/a[1]/span/b').text) # 선작수 추가    \n",
    "\n",
    "# 위의 오류를 고치고 리스트에 저장한 후 데이터프레임을 만들고 저장하는 과정을 거치던 중  \n",
    "# all arrays must be of the same length 오류가 발생하며 데이터프레임이 만들어지지 않고 터져버렸다.  \n",
    "df= pd.DataFrame({\"제목\":Title, \"장르\":Genre, \"작가\":Author, \"연재 시작일\":Start, \"마지막 연재일\":Last, \"회수\":Count, \"조회수\":View, \"추천수\":Good, \"글자수\":Typing, \"선작수\":Favorite})\n",
    "  \n",
    "# 처음엔 반복문이지만 df를 만드는 도중 터져버려서 설마 df를 초기화 해주고 새로 만들어야 하나 싶었고 아래의 코드로 만들 었으나  \n",
    "if targetSite == 'https://www.munpia.com/page/best/section/plsa.eachtoday':  \n",
    "    df_T= pd.DataFrame({\"제목\":Title, \"장르\":Genre, \"작가\":Author, \"연재 시작일\":Start, \"마지막 연재일\":Last, \"회수\":Count, \"조회수\":View, \"추천수\":Good, \"글자수\":Typing, \"선작수\":Favorite})\n",
    "    df_T.to_csv('./data/M_Today_Best.txt')  \n",
    "elif targetSite == 'https://www.munpia.com/page/best/section/plsa.weekly':  \n",
    "    df_W= pd.DataFrame({\"제목\":Title, \"장르\":Genre, \"작가\":Author, \"연재 시작일\":Start, \"마지막 연재일\":Last, \"회수\":Count, \"조회수\":View, \"추천수\":Good, \"글자수\":Typing, \"선작수\":Favorite})\n",
    "    df_W.to_csv('./data/M_Week_Best.txt')  \n",
    "elif targetSite == 'https://www.munpia.com/page/best/section/plsa.monthly':  \n",
    "    df_M= pd.DataFrame({\"제목\":Title, \"장르\":Genre, \"작가\":Author, \"연재 시작일\":Start, \"마지막 연재일\":Last, \"회수\":Count, \"조회수\":View, \"추천수\":Good, \"글자수\":Typing, \"선작수\":Favorite})\n",
    "    df_M.to_csv('./data/M_Month_Best.txt')  \n",
    "else:  \n",
    "    df_N= pd.DataFrame({\"제목\":Title, \"장르\":Genre, \"작가\":Author, \"연재 시작일\":Start, \"마지막 연재일\":Last, \"회수\":Count, \"조회수\":View, \"추천수\":Good, \"글자수\":Typing, \"선작수\":Favorite})\n",
    "    df_N.to_csv('./data/M_New_Best.txt')   \n",
    "# 위의 코드도 데이터 프레임을 만드는 도중 같은 위치에서 오류가 발생했다.  \n",
    "\n",
    "# 아래의 코드를 통해 all arrays must be of the same length 오류가 발생한 원인을 찾았는데 200으로 동일해야 하는 Author 리스트의 숫자가 200보다 더 컸다.  \n",
    "print(len(Title), len(Genre), len(Author), len(Favorite), len(Start), len(Last), len(Count), len(View), len(Good), len(Typing))  \n",
    "\n",
    "# 위에서 고쳤던 아래의 코드에서 문제가 발생했던 것으로 선작수에서 오류가 발생해 except로 넘어갈 때 다시 작가가 한번 더 추가되어 200개 이상+ 중복된 작가가  \n",
    "# 추가되었고 위의 all arrays must be of the same length 오류가 발생한 것.  \n",
    "try:    \n",
    "    Author.append(driver.find_element(By.XPATH, '//*[@id=\"board\"]/div[1]/div[3]/dl[1]/dd/a/strong').text) # 작가 추가    \n",
    "    Favorite.append(driver.find_element(By.XPATH, '//*[@id=\"board\"]/div[1]/div[3]/div[2]/div[2]/a[1]/span/b').text) # 선작수 추가    \n",
    "except:    \n",
    "    Author.append(driver.find_element(By.XPATH, '//*[@id=\"board\"]/div[1]/div[3]/dl[1]/dd').text) # 작가 추가    \n",
    "    Favorite.append(driver.find_element(By.XPATH, '//*[@id=\"board\"]/div[1]/div[3]/div/div[2]/a[1]/span/b').text) # 선작수 추가  \n",
    "    \n",
    "# 간단하게 둘을 try,except를 2번 써서 고쳤다.  \n",
    "try:  \n",
    "    Author.append(driver.find_element(By.XPATH, '//*[@id=\"board\"]/div[1]/div[3]/dl[1]/dd/a/strong').text) # 작가 추가  \n",
    "except:  \n",
    "    Author.append(driver.find_element(By.XPATH, '//*[@id=\"board\"]/div[1]/div[3]/dl[1]/dd').text) # 작가 추가   \n",
    "try:  \n",
    "    Favorite.append(driver.find_element(By.XPATH, '//*[@id=\"board\"]/div[1]/div[3]/div[2]/div[2]/a[1]/span/b').text) # 선작수 추가  \n",
    "except:  \n",
    "    Favorite.append(driver.find_element(By.XPATH, '//*[@id=\"board\"]/div[1]/div[3]/div/div[2]/a[1]/span/b').text) # 선작수 추가  \n",
    "      \n",
    "# 정상적으로 데이터 프레임이 만들어 졌지만 index가 0부터 시작하는 게 마음에 안들고 순위권을 나타내기 위해서 아래의 코드를 추가했다.  \n",
    "df.index = df.index+1  \n",
    "\n",
    "# 전체적으로 4번 반복 해야해서 targetSites 리스트를 만들고 반복문으로 돌려서 길이를 줄였다.  \n",
    "targetSites = ['https://www.munpia.com/page/best/section/plsa.eachtoday', 'https://www.munpia.com/page/best/section/plsa.weekly',\n",
    "               'https://www.munpia.com/page/best/section/plsa.monthly', 'https://www.munpia.com/page/best/section/plsa.newbie']  \n",
    "\n",
    "for targetSite in targetSites:    \n",
    "   \n",
    "# 코딩된 작업물이 동작하는 시간을 보기 위해서 아래의 코드를 추가 했다. 729개의 소설 데이터를 크롤링 하는데 13분 정도 걸렸다.  \n",
    "start=time.time()  \n",
    "end=time.time()       \n",
    "print(end-start) # 782.0946562290192  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006f479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47dff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e73d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86520f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e2639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
